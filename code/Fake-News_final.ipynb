{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NUS_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwinvaswani/Fake-News-Detection/blob/master/code/Fake-News_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY7DvNi__vKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NUS Fake news detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8jH95jj_4nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the solution to the fake news classification problem"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th1m1YjDAAFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T95oZ-1dABqV",
        "colab_type": "code",
        "outputId": "94e5b637-79ec-4efe-d094-d80e46750c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "import seaborn as sn\n",
        "from sklearn.model_selection import *\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.linear_model import *\n",
        "from sklearn.ensemble import *\n",
        "from sklearn.metrics import *\n",
        "from sklearn.externals import *\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.svm import *\n",
        "from sklearn.utils import shuffle\n",
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "from dateutil.parser import parse\n",
        "import datetime as dt\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import *\n",
        "from textblob import TextBlob, Word\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPunEMYXAIm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Multi class classification :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJSi03KaAD7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleaner(df, b=True):\n",
        "    df.columns = ['label', 'statement', 'subject', 'speaker', 'speakerTitle', 'state', 'party',\n",
        "                  'barely-true', 'false', 'half-true', 'mostly-true', 'pants-fire', 'context', 'justification']\n",
        "    \n",
        "    stemmer = nltk.stem.PorterStemmer()\n",
        "    Stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "    values_nan = {'subject': 'unknown', 'speaker': 'unknown', 'speakerTitle': 'unknown', 'state': 'unknown',\n",
        "                  'party': 'unknown', 'barely-true': 0.0, 'false': 0.0, 'half-true': 0.0, 'mostly-true': 0.0,\n",
        "                  'pants-fire': 0.0, 'context': 'unknown', 'justification': 'unknown'}\n",
        "    df.fillna(value=values_nan, inplace=True)\n",
        "\n",
        "    if b:\n",
        "        df.label.replace(\n",
        "            {'half-true': 1, 'mostly-true': 1, 'false': 0, 'true': 1, 'barely-true': 0, 'pants-fire': 0},\n",
        "            inplace=True)\n",
        "    else:\n",
        "        df.label.replace(\n",
        "            {'half-true': 2, 'mostly-true': 1, 'false': 4, 'true': 0, 'barely-true': 3, 'pants-fire': 5},\n",
        "            inplace=True)\n",
        "\n",
        "    df['statement'] = df['statement'].apply(lambda x: ' '.join([word for word in x.split() if word not in Stopwords]))\n",
        "    df['statement'] = df['statement'].apply(lambda x: stemmer.stem(x))\n",
        "\n",
        "    df['context'] = df['context'].apply(lambda x: ' '.join([word for word in x.split() if word not in Stopwords]))\n",
        "    df['context'] = df['context'].apply(lambda x: stemmer.stem(x))\n",
        "\n",
        "    df['justification'] = df['justification'].apply(lambda x: ' '.join([word for word in x.split() if word not in Stopwords]))\n",
        "    df['justification'] = df['justification'].apply(lambda x: stemmer.stem(x))\n",
        "\n",
        "    df['speaker'] = df['speaker'].apply(lambda x: x.replace('-', ''))\n",
        "    speaker_dict = dict()\n",
        "    for i, speaker in enumerate(pd.unique(df['speaker'])):\n",
        "        speaker_dict[speaker] = i\n",
        "\n",
        "    df.speaker.replace(speaker_dict, inplace=True)\n",
        "\n",
        "    speaker_title_dict = dict()\n",
        "    for i, speakerTitle in enumerate(pd.unique(df['speakerTitle'])):\n",
        "        speaker_title_dict[speakerTitle] = i\n",
        "\n",
        "    df.speakerTitle.replace(speaker_title_dict, inplace=True)\n",
        "\n",
        "    state_dict = dict()\n",
        "    for i, state in enumerate(pd.unique(df['state'])):\n",
        "        state_dict[state] = i\n",
        "\n",
        "    df.state.replace(state_dict, inplace=True)\n",
        "\n",
        "    party_dict = dict()\n",
        "    for i, party in enumerate(pd.unique(df['party'])):\n",
        "        party_dict[party] = i\n",
        "\n",
        "    df.party.replace(party_dict, inplace=True)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_9Te5zUC4FX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data_dl(hd_df, col_name):\n",
        "\n",
        "    hd_df[col_name] = hd_df[col_name].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "    # Removing tags\n",
        "    hd_df[col_name] = hd_df[col_name].str.replace('<.*?>','')\n",
        "\n",
        "    # Removing possible mentions or urls (don't know if it's necessary but might be) \n",
        "    hd_df[col_name] = hd_df[col_name].str.replace('@\\w+','')\n",
        "    hd_df[col_name] = hd_df[col_name].str.replace('http.?://[^\\s]+[\\s]?','')\n",
        "\n",
        "    # Removing punctuation and symbols\n",
        "    hd_df[col_name] = hd_df[col_name].str.replace('[^\\w\\s]', '')\n",
        "    hd_df[col_name] = hd_df[col_name].apply(lambda x: \" \".join(x for x in x.split() if x not in string.punctuation))\n",
        "\n",
        "    # Removing non alphabetical character\n",
        "    hd_df[col_name] = hd_df[col_name].apply(lambda x: \" \".join(x for x in x.split() if x.isalpha()))\n",
        "\n",
        "    # Removing characters non longer than 1\n",
        "    hd_df[col_name] = hd_df[col_name].apply(lambda x: \" \".join(x for x in x.split() if len(x) > 1))\n",
        "\n",
        "    # Removing stopwords\n",
        "    sw = stopwords.words('english')\n",
        "    hd_df[col_name] = hd_df[col_name].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
        "\n",
        "    # Removing digits\n",
        "    hd_df[col_name] = hd_df[col_name].apply(lambda x: \" \".join(x for x in x.split() if not x.isdigit()))\n",
        "\n",
        "    # Removing words that appear less than 5\n",
        "    word_freq = pd.Series(' '.join(hd_df[col_name]).split()).value_counts()\n",
        "    less_freq = word_freq[word_freq < 5]\n",
        "    hd_df[col_name] = hd_df[col_name].apply(lambda x: \" \".join(x for x in x.split() if x not in less_freq))\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    hd_df[col_name] = hd_df[col_name].apply(lambda x: x.strip())\n",
        "    hd_df[col_name] = hd_df[col_name].str.replace(' +',' ')\n",
        "\n",
        "    # Lemmatization (better than stemmatization imho)\n",
        "    hd_df[col_name] = hd_df[col_name].apply(lambda x: \" \".join([Word(w).lemmatize() for w in x.split()]))\n",
        "\n",
        "\n",
        "    return hd_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfyHQZAiAMpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['serialNo', 'ID', 'label', 'statement', 'subject', 'speaker', 'speakerTitle', 'state', 'party',\n",
        "                  'barely-true', 'false', 'half-true', 'mostly-true', 'pants-fire', 'context', 'justification']\n",
        "\n",
        "train_data = pd.read_csv('train2.tsv', delimiter='\\t',names = columns)\n",
        "test_data = pd.read_csv('test2.tsv', delimiter='\\t',names = columns)\n",
        "val_data = pd.read_csv('val2.tsv', delimiter='\\t', names= columns)\n",
        "\n",
        "train_data = train_data.drop(['ID','serialNo'],axis = 1)\n",
        "test_data = test_data.drop(['ID','serialNo'],axis = 1)\n",
        "val_data = val_data.drop(['ID','serialNo'],axis = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlFkM444AvgJ",
        "colab_type": "code",
        "outputId": "273c43e9-9bb8-4a76-9250-8a3257ce2ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subject</th>\n",
              "      <th>speaker</th>\n",
              "      <th>speakerTitle</th>\n",
              "      <th>state</th>\n",
              "      <th>party</th>\n",
              "      <th>barely-true</th>\n",
              "      <th>false</th>\n",
              "      <th>half-true</th>\n",
              "      <th>mostly-true</th>\n",
              "      <th>pants-fire</th>\n",
              "      <th>context</th>\n",
              "      <th>justification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>false</td>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>dwayne-bohac</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a mailer</td>\n",
              "      <td>That's a premise that he fails to back up. Ann...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a floor speech.</td>\n",
              "      <td>Surovell said the decline of coal \"started whe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mostly-true</td>\n",
              "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
              "      <td>foreign-policy</td>\n",
              "      <td>barack-obama</td>\n",
              "      <td>President</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>democrat</td>\n",
              "      <td>70.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Denver</td>\n",
              "      <td>Obama said he would have voted against the ame...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>false</td>\n",
              "      <td>Health care reform legislation is likely to ma...</td>\n",
              "      <td>health-care</td>\n",
              "      <td>blog-posting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>a news release</td>\n",
              "      <td>The release may have a point that Mikulskis co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>half-true</td>\n",
              "      <td>The economic turnaround started at the end of ...</td>\n",
              "      <td>economy,jobs</td>\n",
              "      <td>charlie-crist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Florida</td>\n",
              "      <td>democrat</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>an interview on CNN</td>\n",
              "      <td>Crist said that the economic \"turnaround start...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         label  ...                                      justification\n",
              "0        false  ...  That's a premise that he fails to back up. Ann...\n",
              "1    half-true  ...  Surovell said the decline of coal \"started whe...\n",
              "2  mostly-true  ...  Obama said he would have voted against the ame...\n",
              "3        false  ...  The release may have a point that Mikulskis co...\n",
              "4    half-true  ...  Crist said that the economic \"turnaround start...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nfCj8MpCB_x",
        "colab_type": "code",
        "outputId": "b06a6d1f-1bba-4c7d-a8e0-92555e8d4954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10240, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PdedJH9A9L6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = cleaner(train_data,b = False)\n",
        "test_data = cleaner(test_data,b = False)\n",
        "val_data = cleaner(val_data,b = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bPVDVwGBl86",
        "colab_type": "code",
        "outputId": "45dfb46f-3774-4e9c-d935-347c43ed8c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subject</th>\n",
              "      <th>speaker</th>\n",
              "      <th>speakerTitle</th>\n",
              "      <th>state</th>\n",
              "      <th>party</th>\n",
              "      <th>barely-true</th>\n",
              "      <th>false</th>\n",
              "      <th>half-true</th>\n",
              "      <th>mostly-true</th>\n",
              "      <th>pants-fire</th>\n",
              "      <th>context</th>\n",
              "      <th>justification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>says annies list political group supports thir...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>mailer</td>\n",
              "      <td>that's premise fails back up. annie's list mak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>when decline coal start? it started natural ga...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>floor speech.</td>\n",
              "      <td>surovell said decline coal \"started natural ga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>hillary clinton agrees john mccain \"by voting ...</td>\n",
              "      <td>foreign-policy</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>70.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>denver</td>\n",
              "      <td>obama said would voted amendment present. so t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>health care reform legislation likely mandate ...</td>\n",
              "      <td>health-care</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>news releas</td>\n",
              "      <td>the release may point mikulskis comment could ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>the economic turnaround started end term.</td>\n",
              "      <td>economy,jobs</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>interview cnn</td>\n",
              "      <td>crist said economic \"turnaround started end te...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                      justification\n",
              "0      4  ...  that's premise fails back up. annie's list mak...\n",
              "1      2  ...  surovell said decline coal \"started natural ga...\n",
              "2      1  ...  obama said would voted amendment present. so t...\n",
              "3      4  ...  the release may point mikulskis comment could ...\n",
              "4      2  ...  crist said economic \"turnaround started end te...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngiBFA-dCZzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = clean_data_dl(train_data,\"statement\")\n",
        "train_data = clean_data_dl(train_data,\"subject\")\n",
        "train_data = clean_data_dl(train_data,\"context\")\n",
        "train_data = clean_data_dl(train_data,\"justification\")\n",
        "\n",
        "test_data = clean_data_dl(test_data,\"statement\")\n",
        "test_data = clean_data_dl(test_data,\"subject\")\n",
        "test_data = clean_data_dl(test_data,\"context\")\n",
        "test_data = clean_data_dl(test_data,\"justification\")\n",
        "\n",
        "val_data = clean_data_dl(val_data,\"subject\")\n",
        "val_data = clean_data_dl(val_data,\"context\")\n",
        "val_data = clean_data_dl(val_data,\"justification\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKGZojF-DZZ1",
        "colab_type": "code",
        "outputId": "f56d2564-ecd1-4742-8417-062ebc526d9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subject</th>\n",
              "      <th>speaker</th>\n",
              "      <th>speakerTitle</th>\n",
              "      <th>state</th>\n",
              "      <th>party</th>\n",
              "      <th>barely-true</th>\n",
              "      <th>false</th>\n",
              "      <th>half-true</th>\n",
              "      <th>mostly-true</th>\n",
              "      <th>pants-fire</th>\n",
              "      <th>context</th>\n",
              "      <th>justification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>say list political group support abortion demand</td>\n",
              "      <td>abortion</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>mailer</td>\n",
              "      <td>thats premise fails back list make comfortable...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>decline coal start started natural gas took st...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>floor speech</td>\n",
              "      <td>said decline coal started natural gas took sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>hillary clinton john mccain voting give george...</td>\n",
              "      <td>foreignpolicy</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>70.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>denver</td>\n",
              "      <td>obama said would voted amendment present thoug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>health care reform legislation likely mandate ...</td>\n",
              "      <td>healthcare</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>news releas</td>\n",
              "      <td>release may point comment could open door medi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>economic started end term</td>\n",
              "      <td>economyjobs</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>interview cnn</td>\n",
              "      <td>crist said economic turnaround started end ter...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                      justification\n",
              "0      4  ...  thats premise fails back list make comfortable...\n",
              "1      2  ...  said decline coal started natural gas took sta...\n",
              "2      1  ...  obama said would voted amendment present thoug...\n",
              "3      4  ...  release may point comment could open door medi...\n",
              "4      2  ...  crist said economic turnaround started end ter...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8BDJn9yGYJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Machine Learning approches :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzK58RvCEBIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Logistic regression with all features :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyaIvCYyEOqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_logisticregression(train_data, val_data, test_data):\n",
        "    vectorizer_statement = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                           lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_subject = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                         lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_context = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                         lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_justification = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                               lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.fit_transform(train_data['statement']).toarray()\n",
        "    subject_onehotvector = vectorizer_subject.fit_transform(train_data['subject']).toarray()\n",
        "    context_onehotvector = vectorizer_context.fit_transform(train_data['context']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.fit_transform(train_data['justification']).toarray()\n",
        "\n",
        "    X_train, y_train = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(subject_onehotvector), train_data.iloc[:, 3:12],\n",
        "         pd.DataFrame(context_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), train_data[\n",
        "                           'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(val_data['statement']).toarray()\n",
        "    subject_onehotvector = vectorizer_subject.transform(val_data['subject']).toarray()\n",
        "    context_onehotvector = vectorizer_context.transform(val_data['context']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(val_data['justification']).toarray()\n",
        "\n",
        "    X_val, y_val = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(subject_onehotvector), val_data.iloc[:, 3:12],\n",
        "         pd.DataFrame(context_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), val_data[\n",
        "                       'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(test_data['statement']).toarray()\n",
        "    subject_onehotvector = vectorizer_subject.transform(test_data['subject']).toarray()\n",
        "    context_onehotvector = vectorizer_context.transform(test_data['context']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(test_data['justification']).toarray()\n",
        "\n",
        "    X_test, y_test = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(subject_onehotvector), test_data.iloc[:, 3:12],\n",
        "         pd.DataFrame(context_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), test_data[\n",
        "                         'label'].astype('int')\n",
        "\n",
        "    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "    clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=250)\n",
        "    print(\"\\n\\n============ Model Summary ============\")\n",
        "    print(clf)\n",
        "\n",
        "    print(\"\\n\\n============ Model Training ============\")\n",
        "    clf = clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\n\\n============ Model Evaluation ============\")\n",
        "    scores = clf.score(X_val, y_val)\n",
        "    print(\"Validation data Accuracy:\", scores)\n",
        "    scores = clf.score(X_test, y_test)\n",
        "    print(\"Test data Accuracy:\", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QZY_Z1lEymx",
        "colab_type": "code",
        "outputId": "0d3ee6ac-8adc-4c96-bb06-aeaf5d4fa3b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "model_logisticregression(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 6597) (10240,) (1284, 6597) (1284,) (1267, 6597) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
            "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.3341121495327103\n",
            "Test data Accuracy: 0.3007103393843725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a50AJmeTE3nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Logistic Regression without subject and context :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1yaz626FZVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_logisticregression_withoutSC(train_data, val_data, test_data):\n",
        "    vectorizer_statement = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                           lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_justification = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                               lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.fit_transform(train_data['statement']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.fit_transform(train_data['justification']).toarray()\n",
        "\n",
        "    X_train, y_train = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), train_data.iloc[:, 3:12], pd.DataFrame(justification_onehotvector)], axis=1), train_data[\n",
        "                           'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(val_data['statement']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(val_data['justification']).toarray()\n",
        "\n",
        "    X_val, y_val = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), val_data.iloc[:, 3:12],pd.DataFrame(justification_onehotvector)], axis=1), val_data[\n",
        "                       'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(test_data['statement']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(test_data['justification']).toarray()\n",
        "\n",
        "    X_test, y_test = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), test_data.iloc[:, 3:12],pd.DataFrame(justification_onehotvector)], axis=1), test_data[\n",
        "                         'label'].astype('int')\n",
        "\n",
        "    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "    clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=250)\n",
        "    print(\"\\n\\n============ Model Summary ============\")\n",
        "    print(clf)\n",
        "\n",
        "    print(\"\\n\\n============ Model Training ============\")\n",
        "    clf = clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\n\\n============ Model Evaluation ============\")\n",
        "    scores = clf.score(X_val, y_val)\n",
        "    print(\"Validation data Accuracy:\", scores)\n",
        "    scores = clf.score(X_test, y_test)\n",
        "    print(\"Test data Accuracy:\", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAvNvwYCGP2V",
        "colab_type": "code",
        "outputId": "77bc0283-749d-480e-8983-98a2a724327a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "model_logisticregression_withoutSC(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 5790) (10240,) (1284, 5790) (1284,) (1267, 5790) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=250,\n",
            "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.34579439252336447\n",
            "Test data Accuracy: 0.31570639305445936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZHTjGhfGhcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Logistic Regression with only SMJ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHdO-VJEGkcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_logisticregression_SMJ(train_data, val_data, test_data):\n",
        "    vectorizer_statement = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                           lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_subject = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                         lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_context = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                         lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_justification = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                               lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.fit_transform(train_data['statement']).toarray()\n",
        "    subject_onehotvector = vectorizer_subject.fit_transform(train_data['subject']).toarray()\n",
        "    context_onehotvector = vectorizer_context.fit_transform(train_data['context']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.fit_transform(train_data['justification']).toarray()\n",
        "\n",
        "    X_train, y_train = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(subject_onehotvector),\n",
        "         pd.DataFrame(context_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), train_data[\n",
        "                           'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(val_data['statement']).toarray()\n",
        "    subject_onehotvector = vectorizer_subject.transform(val_data['subject']).toarray()\n",
        "    context_onehotvector = vectorizer_context.transform(val_data['context']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(val_data['justification']).toarray()\n",
        "\n",
        "    X_val, y_val = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(subject_onehotvector), \n",
        "         pd.DataFrame(context_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), val_data[\n",
        "                       'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(test_data['statement']).toarray()\n",
        "    subject_onehotvector = vectorizer_subject.transform(test_data['subject']).toarray()\n",
        "    context_onehotvector = vectorizer_context.transform(test_data['context']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(test_data['justification']).toarray()\n",
        "\n",
        "    X_test, y_test = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(subject_onehotvector),\n",
        "         pd.DataFrame(context_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), test_data[\n",
        "                         'label'].astype('int')\n",
        "\n",
        "    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "\n",
        "    clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=250)\n",
        "    print(\"\\n\\n============ Model Summary ============\")\n",
        "    print(clf)\n",
        "\n",
        "    print(\"\\n\\n============ Model Training ============\")\n",
        "    clf = clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\n\\n============ Model Evaluation ============\")\n",
        "    scores = clf.score(X_val, y_val)\n",
        "    print(\"Validation data Accuracy:\", scores)\n",
        "    scores = clf.score(X_test, y_test)\n",
        "    print(\"Test data Accuracy:\", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2dC8GHAG1-7",
        "colab_type": "code",
        "outputId": "40cfe0e7-0fe6-4667-900f-a0b05f8d6e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "model_logisticregression_SMJ(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 6588) (10240,) (1284, 6588) (1284,) (1267, 6588) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=250,\n",
            "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.2531152647975078\n",
            "Test data Accuracy: 0.2265193370165746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCIS91dMIo1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Logistic Regression with only SJ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHh3UN8LHDrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_logisticregression_SJ(train_data, val_data, test_data):\n",
        "    vectorizer_statement = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                           lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_justification = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                               lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.fit_transform(train_data['statement']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.fit_transform(train_data['justification']).toarray()\n",
        "\n",
        "    X_train, y_train = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), train_data[\n",
        "                           'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(val_data['statement']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(val_data['justification']).toarray()\n",
        "\n",
        "    X_val, y_val = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector),pd.DataFrame(justification_onehotvector)], axis=1), val_data[\n",
        "                       'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(test_data['statement']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(test_data['justification']).toarray()\n",
        "\n",
        "    X_test, y_test = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector),pd.DataFrame(justification_onehotvector)], axis=1), test_data[\n",
        "                         'label'].astype('int')\n",
        "\n",
        "    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "    clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=250)\n",
        "    print(\"\\n\\n============ Model Summary ============\")\n",
        "    print(clf)\n",
        "\n",
        "    print(\"\\n\\n============ Model Training ============\")\n",
        "    clf = clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\n\\n============ Model Evaluation ============\")\n",
        "    scores = clf.score(X_val, y_val)\n",
        "    print(\"Validation data Accuracy:\", scores)\n",
        "    scores = clf.score(X_test, y_test)\n",
        "    print(\"Test data Accuracy:\", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5QEmrMCHscW",
        "colab_type": "code",
        "outputId": "def72497-8469-4b46-9798-19d1863c83f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "model_logisticregression_SJ(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 5781) (10240,) (1284, 5781) (1284,) (1267, 5781) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=250,\n",
            "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.2250778816199377\n",
            "Test data Accuracy: 0.21625887924230466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyMCRnnoHw-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using ensemling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxQXinyEIB7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gradient Boosting with all features "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgMXcw_WIGDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gradientboost(train_data, val_data, test_data):\n",
        "    vectorizer_statement = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                           lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_subject = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                         lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_context = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                         lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_justification = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                               lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.fit_transform(train_data['statement']).toarray()\n",
        "    subject_onehotvector = vectorizer_subject.fit_transform(train_data['subject']).toarray()\n",
        "    context_onehotvector = vectorizer_context.fit_transform(train_data['context']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.fit_transform(train_data['justification']).toarray()\n",
        "\n",
        "    X_train, y_train = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(subject_onehotvector), train_data.iloc[:, 3:12],\n",
        "         pd.DataFrame(context_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), train_data[\n",
        "                           'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(val_data['statement']).toarray()\n",
        "    subject_onehotvector = vectorizer_subject.transform(val_data['subject']).toarray()\n",
        "    context_onehotvector = vectorizer_context.transform(val_data['context']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(val_data['justification']).toarray()\n",
        "\n",
        "    X_val, y_val = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(subject_onehotvector), val_data.iloc[:, 3:12],\n",
        "         pd.DataFrame(context_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), val_data[\n",
        "                       'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(test_data['statement']).toarray()\n",
        "    subject_onehotvector = vectorizer_subject.transform(test_data['subject']).toarray()\n",
        "    context_onehotvector = vectorizer_context.transform(test_data['context']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(test_data['justification']).toarray()\n",
        "\n",
        "    X_test, y_test = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(subject_onehotvector), test_data.iloc[:, 3:12],\n",
        "         pd.DataFrame(context_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), test_data[\n",
        "                         'label'].astype('int')\n",
        "\n",
        "    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "    gb = GradientBoostingClassifier()\n",
        "    print(\"\\n\\n============ Model Summary ============\")\n",
        "    print(gb)\n",
        "\n",
        "    print(\"\\n\\n============ Model Training ============\")\n",
        "    gb = gb.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\n\\n============ Model Evaluation ============\")\n",
        "    scores = gb.score(X_val, y_val)\n",
        "    print(\"Validation data Accuracy:\", scores)\n",
        "    scores = gb.score(X_test, y_test)\n",
        "    print(\"Test data Accuracy:\", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdgL6xgiIa_g",
        "colab_type": "code",
        "outputId": "5a88c267-4189-4a3a-b43f-840f090baed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "model_gradientboost(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 6597) (10240,) (1284, 6597) (1284,) (1267, 6597) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='auto',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.4501557632398754\n",
            "Test data Accuracy: 0.4293606945540647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF8Px2OkIhKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Gradient boosting without context and subject"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwuF1FifIluQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gradientboost_withoutSC(train_data, val_data, test_data):\n",
        "    vectorizer_statement = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                           lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_justification = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                               lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.fit_transform(train_data['statement']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.fit_transform(train_data['justification']).toarray()\n",
        "\n",
        "    X_train, y_train = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), train_data.iloc[:, 3:12], pd.DataFrame(justification_onehotvector)], axis=1), train_data[\n",
        "                           'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(val_data['statement']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(val_data['justification']).toarray()\n",
        "\n",
        "    X_val, y_val = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), val_data.iloc[:, 3:12],pd.DataFrame(justification_onehotvector)], axis=1), val_data[\n",
        "                       'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(test_data['statement']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(test_data['justification']).toarray()\n",
        "\n",
        "    X_test, y_test = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), test_data.iloc[:, 3:12],pd.DataFrame(justification_onehotvector)], axis=1), test_data[\n",
        "                         'label'].astype('int')\n",
        "\n",
        "    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "    gb = GradientBoostingClassifier()\n",
        "    print(\"\\n\\n============ Model Summary ============\")\n",
        "    print(gb)\n",
        "\n",
        "    print(\"\\n\\n============ Model Training ============\")\n",
        "    gb = gb.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\n\\n============ Model Evaluation ============\")\n",
        "    scores = gb.score(X_val, y_val)\n",
        "    print(\"Validation data Accuracy:\", scores)\n",
        "    scores = gb.score(X_test, y_test)\n",
        "    print(\"Test data Accuracy:\", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwFrGibKJ0VD",
        "colab_type": "code",
        "outputId": "a6e5a586-5826-49f8-93e6-2d647c2491dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "model_gradientboost_withoutSC(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 5790) (10240,) (1284, 5790) (1284,) (1267, 5790) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='auto',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.4649532710280374\n",
            "Test data Accuracy: 0.4238358326756117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhLVb7rRJAcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Gradient Boosting with only SMJ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_QypyPLJE9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gradientboost_SMJ(train_data, val_data, test_data):\n",
        "    vectorizer_statement = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                           lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_subject = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                         lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_context = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                         lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_justification = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                               lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.fit_transform(train_data['statement']).toarray()\n",
        "    subject_onehotvector = vectorizer_subject.fit_transform(train_data['subject']).toarray()\n",
        "    context_onehotvector = vectorizer_context.fit_transform(train_data['context']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.fit_transform(train_data['justification']).toarray()\n",
        "\n",
        "    X_train, y_train = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(subject_onehotvector),\n",
        "         pd.DataFrame(context_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), train_data[\n",
        "                           'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(val_data['statement']).toarray()\n",
        "    subject_onehotvector = vectorizer_subject.transform(val_data['subject']).toarray()\n",
        "    context_onehotvector = vectorizer_context.transform(val_data['context']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(val_data['justification']).toarray()\n",
        "\n",
        "    X_val, y_val = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(subject_onehotvector), \n",
        "         pd.DataFrame(context_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), val_data[\n",
        "                       'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(test_data['statement']).toarray()\n",
        "    subject_onehotvector = vectorizer_subject.transform(test_data['subject']).toarray()\n",
        "    context_onehotvector = vectorizer_context.transform(test_data['context']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(test_data['justification']).toarray()\n",
        "\n",
        "    X_test, y_test = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), pd.DataFrame(subject_onehotvector),\n",
        "         pd.DataFrame(context_onehotvector), pd.DataFrame(justification_onehotvector)], axis=1), test_data[\n",
        "                         'label'].astype('int')\n",
        "\n",
        "    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "\n",
        "    gb = GradientBoostingClassifier()\n",
        "    print(\"\\n\\n============ Model Summary ============\")\n",
        "    print(gb)\n",
        "\n",
        "    print(\"\\n\\n============ Model Training ============\")\n",
        "    gb = gb.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\n\\n============ Model Evaluation ============\")\n",
        "    scores = gb.score(X_val, y_val)\n",
        "    print(\"Validation data Accuracy:\", scores)\n",
        "    scores = gb.score(X_test, y_test)\n",
        "    print(\"Test data Accuracy:\", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCDip8M-J59o",
        "colab_type": "code",
        "outputId": "d6b59fed-2431-4175-9319-91ef77747562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "model_gradientboost_SMJ(train_data, val_data, test_data)%%!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 6588) (10240,) (1284, 6588) (1284,) (1267, 6588) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='auto',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.2484423676012461\n",
            "Test data Accuracy: 0.2494080505130229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDYu1bdaJP27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Gradient Boosting with only SJ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHuZ-qyzJX94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gradientboost_SJ(train_data, val_data, test_data):\n",
        "    vectorizer_statement = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                           lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    vectorizer_justification = CountVectorizer(binary=True, stop_words=nltk.corpus.stopwords.words('english'),\n",
        "                                               lowercase=True, min_df=3, max_df=0.9, max_features=3000)\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.fit_transform(train_data['statement']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.fit_transform(train_data['justification']).toarray()\n",
        "\n",
        "    X_train, y_train = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), train_data.iloc[:, 3:12], pd.DataFrame(justification_onehotvector)], axis=1), train_data[\n",
        "                           'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(val_data['statement']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(val_data['justification']).toarray()\n",
        "\n",
        "    X_val, y_val = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), val_data.iloc[:, 3:12],pd.DataFrame(justification_onehotvector)], axis=1), val_data[\n",
        "                       'label'].astype('int')\n",
        "\n",
        "    statement_onehotvector = vectorizer_statement.transform(test_data['statement']).toarray()\n",
        "    justification_onehotvector = vectorizer_justification.transform(test_data['justification']).toarray()\n",
        "\n",
        "    X_test, y_test = pd.concat(\n",
        "        [pd.DataFrame(statement_onehotvector), test_data.iloc[:, 3:12],pd.DataFrame(justification_onehotvector)], axis=1), test_data[\n",
        "                         'label'].astype('int')\n",
        "\n",
        "    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "    gb = GradientBoostingClassifier()\n",
        "    print(\"\\n\\n============ Model Summary ============\")\n",
        "    print(gb)\n",
        "\n",
        "    print(\"\\n\\n============ Model Training ============\")\n",
        "    gb = gb.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\n\\n============ Model Evaluation ============\")\n",
        "    scores = gb.score(X_val, y_val)\n",
        "    print(\"Validation data Accuracy:\", scores)\n",
        "    scores = gb.score(X_test, y_test)\n",
        "    print(\"Test data Accuracy:\", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8_3wRkQJvUt",
        "colab_type": "code",
        "outputId": "7421b018-854f-4a37-a1fc-e95fd5c21c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "model_gradientboost_SJ(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 5790) (10240,) (1284, 5790) (1284,) (1267, 5790) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='auto',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.4602803738317757\n",
            "Test data Accuracy: 0.4246250986582478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pu7X8y_KEff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deep Learning Approach "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDIzY3xOKG3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpD_lHgHKHuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Binary Classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPPY4lxrKc7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['serialNo', 'ID', 'label', 'statement', 'subject', 'speaker', 'speakerTitle', 'state', 'party',\n",
        "                  'barely-true', 'false', 'half-true', 'mostly-true', 'pants-fire', 'context', 'justification']\n",
        "\n",
        "train_data = pd.read_csv('train2.tsv', delimiter='\\t',names = columns)\n",
        "test_data = pd.read_csv('test2.tsv', delimiter='\\t',names = columns)\n",
        "val_data = pd.read_csv('val2.tsv', delimiter='\\t', names= columns)\n",
        "\n",
        "train_data = train_data.drop(['ID','serialNo'],axis = 1)\n",
        "test_data = test_data.drop(['ID','serialNo'],axis = 1)\n",
        "val_data = val_data.drop(['ID','serialNo'],axis = 1)\n",
        "\n",
        "train_data = cleaner(train_data,b = True)\n",
        "test_data = cleaner(test_data,b = True)\n",
        "val_data = cleaner(val_data,b = True)\n",
        "\n",
        "train_data = clean_data_dl(train_data,\"statement\")\n",
        "train_data = clean_data_dl(train_data,\"subject\")\n",
        "train_data = clean_data_dl(train_data,\"context\")\n",
        "train_data = clean_data_dl(train_data,\"justification\")\n",
        "\n",
        "test_data = clean_data_dl(test_data,\"statement\")\n",
        "test_data = clean_data_dl(test_data,\"subject\")\n",
        "test_data = clean_data_dl(test_data,\"context\")\n",
        "test_data = clean_data_dl(test_data,\"justification\")\n",
        "\n",
        "val_data = clean_data_dl(val_data,\"subject\")\n",
        "val_data = clean_data_dl(val_data,\"context\")\n",
        "val_data = clean_data_dl(val_data,\"justification\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93FUBOWjKnwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feZDbNawKwcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Logistic regression with all features :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X34J6CZJKxJJ",
        "colab_type": "code",
        "outputId": "65568fd6-08c6-490c-d59c-1b68ea0a8dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "model_logisticregression(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 6589) (10240,) (1284, 6589) (1284,) (1267, 6589) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
            "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.5771028037383178\n",
            "Test data Accuracy: 0.5674822415153907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYnrHLsBLILE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Logistic Regression without subject and context :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4kJEk_4LNF7",
        "colab_type": "code",
        "outputId": "0693ad58-8caa-4c60-f6e2-bc89227570f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "model_logisticregression_withoutSC(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 5791) (10240,) (1284, 5791) (1284,) (1267, 5791) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='auto',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.7118380062305296\n",
            "Test data Accuracy: 0.7411207576953434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWUrQ-B7LNSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Logistic Regression with only SMJ :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReqaRoxkLYeo",
        "colab_type": "code",
        "outputId": "b4491e1c-1be0-48f0-f5e1-647f194aa1d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "model_logisticregression_SMJ(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 6589) (10240,) (1284, 6589) (1284,) (1267, 6589) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=250,\n",
            "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.5771028037383178\n",
            "Test data Accuracy: 0.5674822415153907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjC646jRLYoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Logistic Regression with only SJ:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95hUYauULcJz",
        "colab_type": "code",
        "outputId": "04263c0b-0143-4660-a84e-24366a6d1daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "model_logisticregression_SJ(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 5782) (10240,) (1284, 5782) (1284,) (1267, 5782) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=250,\n",
            "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.572429906542056\n",
            "Test data Accuracy: 0.569060773480663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S82k7AomLcOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Gradient Boosting with all features :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b0tpzbzLgtj",
        "colab_type": "code",
        "outputId": "46abbb5f-0f5b-4936-89d6-0a67a6566a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "model_gradientboost(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 6598) (10240,) (1284, 6598) (1284,) (1267, 6598) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='auto',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.7048286604361371\n",
            "Test data Accuracy: 0.744277821625888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYaYASfQLhMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Gradient Boosting without subject and context:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZy9OftNLixj",
        "colab_type": "code",
        "outputId": "14e9a063-f14c-480d-9c7b-677f368ab416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "model_gradientboost_withoutSC(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 5791) (10240,) (1284, 5791) (1284,) (1267, 5791) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='auto',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.7118380062305296\n",
            "Test data Accuracy: 0.7411207576953434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq9TzyBqLi5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Gradient Boosting with only SMJ :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYNcE5RuLjk0",
        "colab_type": "code",
        "outputId": "f1e8e452-ff09-4349-a771-a63398f839fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "model_gradientboost_SMJ(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 6589) (10240,) (1284, 6589) (1284,) (1267, 6589) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='auto',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.5654205607476636\n",
            "Test data Accuracy: 0.590370955011839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4AEWUyxLjtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Gradient Boosting with only SJ :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBgd2sSsMKeM",
        "colab_type": "code",
        "outputId": "06c10603-e865-48ba-ca5b-a1ae37ee00ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "model_gradientboost_SJ(train_data, val_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10240, 5791) (10240,) (1284, 5791) (1284,) (1267, 5791) (1267,)\n",
            "\n",
            "\n",
            "============ Model Summary ============\n",
            "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='auto',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "\n",
            "\n",
            "============ Model Training ============\n",
            "\n",
            "\n",
            "============ Model Evaluation ============\n",
            "Validation data Accuracy: 0.7118380062305296\n",
            "Test data Accuracy: 0.7411207576953434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NweyOjAMMMYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}